# ðŸ©º Medical RAG Chatbot (Groq + LangChain + FAISS + Hugging Face)

A **Retrieval-Augmented Generation (RAG)** based **Medical Chatbot** built using **Groq**, **LangChain**, **FAISS**, and **Hugging Face embeddings**.  
The chatbot answers medical questions based on relevant context retrieved from local documents and can optionally **remember past conversations** using conversational memory.

---

##  Features

âœ… **Retrieval-Augmented Generation (RAG)** â€” Combines LLM intelligence with domain-specific medical data stored in FAISS.  
âœ… **Conversational Memory (Optional)** â€” Maintains chat context for more natural, coherent interactions.  
âœ… **Groq-Powered LLMs** â€” Uses `llama-3.1-8b-instant` for fast, accurate responses.  
âœ… **Local Vector Search** â€” FAISS is used for efficient semantic search on medical text data.  
âœ… **Streamlit UI** â€” Interactive, simple chat interface with message history.  
âœ… **Secure API Key Handling** â€” Uses `.env` file to manage the Groq API key securely.

---

##  Architecture Overview

User Query
â”‚
â–¼
Chat Interface (Streamlit)
â”‚
â–¼
Retriever (FAISS + HuggingFace Embeddings)
â”‚
â–¼
Groq LLM (Llama 3.1)
â”‚
â–¼
Final Answer (with optional conversation memory)



## Components Used

| Component | Purpose |
|------------|----------|
| **Groq API** | To access high-speed Llama 3.1 model for response generation |
| **LangChain** | To manage RAG pipeline and memory |
| **FAISS** | Vector store for semantic document retrieval |
| **Hugging Face Embeddings** | To convert medical documents into vector embeddings |
| **FLASK** | To build the chatbot interface |
| **Python Dotenv** | For environment variable management |

---
